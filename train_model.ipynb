{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCOBERTAS:\n",
    "- VIP importa\n",
    "    * ~50% dos Não-VIPs são transportados\n",
    "    * ~38% dos VIPs são transportados\n",
    "    * Terra implica Não-VIP\n",
    "    * Mas está baixo na lista de prioridade para ser transportado\n",
    "        * Europa -> ~65% Transportados\n",
    "        * Earth -> ~41% Transportados -> é o HomePlanet com maior número de pessoas (3566) e todas são NÃO-VIPs\n",
    "        * Mars -> ~53% Transportados\n",
    "- Usando cabines para os planetas\n",
    "    * A B C T -> Europa\n",
    "    * G -> Earth\n",
    "- Cryosleep True ou age <= 12 implica nenhum gasto\n",
    "- Qualquer gasto implica em Cryosleep False\n",
    "- Msm grupo -> Msm Planeta\n",
    "- Msm sobrenome -> Msm Planeta\n",
    "\n",
    "### TESTAR\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0001\n",
       "1       0002\n",
       "2       0003\n",
       "3       0003\n",
       "4       0004\n",
       "        ... \n",
       "8688    9276\n",
       "8689    9278\n",
       "8690    9279\n",
       "8691    9280\n",
       "8692    9280\n",
       "Name: Groups, Length: 8693, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\").dropna()\n",
    "\n",
    "\n",
    "def getGroup(index):\n",
    "    return df['PassengerId'].split('_')[0]\n",
    "#formatting data TODO ISSO VEM POR ULTIMO\n",
    "df['Transported'] = df['Transported'].map({False: 0, True: 1})\n",
    "df['Earth'] = np.select([df['HomePlanet'] == 'Earth'], [1], default = 0)\n",
    "df['Europa'] = np.select([df['HomePlanet'] == 'Europa'], [1], default = 0)\n",
    "df['Mars'] = np.select([df['HomePlanet'] == 'Mars'], [1], default = 0)\n",
    "df['CryoSleep'] = np.select([df['CryoSleep'] == True], [1], default = 0)\n",
    "df['VIP'] = np.select([df['VIP'] == True], [1], default = 0)\n",
    "df['TRAP'] = np.select([df['Destination'] == 'TRAPPIST-1e'], [1], default = 0)\n",
    "df['PSO'] = np.select([df['Destination'] == 'PSO J318.5-22'], [1], default = 0)\n",
    "df['Cancri'] = np.select([df['Destination'] == '55 Cancri e'], [1], default = 0)\n",
    "groups = []\n",
    "for i in range(len(df)):\n",
    "    groups.append((df['PassengerId'][i]).split('_')[0])\n",
    "df['Groups'] = groups\n",
    "df['Groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps us prove that everybody with the same last name has the same Home Planet.\n",
    "# The same applies to passenger groups.\n",
    "def buildHomePlanetDict(column, char, pos, dff):\n",
    "    '''Function that builds a dictionary that follows a <column, set<planets>> relation'''\n",
    "    dictionary = {}\n",
    "    for i in range(len(dff)):\n",
    "        try:\n",
    "            current = dff[column][i].split(char)[pos]\n",
    "            if current not in dictionary:\n",
    "                dictionary[current] = set()\n",
    "            if pd.isnull(dff['HomePlanet'][i]) == False:\n",
    "                dictionary[current].add(dff['HomePlanet'][i])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return dictionary\n",
    "\n",
    "groupDict = buildHomePlanetDict('PassengerId', '_', 0, df)\n",
    "nameDict = buildHomePlanetDict('Name', ' ', 1, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age  VIP  \\\n",
      "0        0001_01     Europa          0     B/0/P    TRAPPIST-1e  39.0    0   \n",
      "1        0002_01      Earth          0     F/0/S    TRAPPIST-1e  24.0    0   \n",
      "2        0003_01     Europa          0     A/0/S    TRAPPIST-1e  58.0    1   \n",
      "3        0003_02     Europa          0     A/0/S    TRAPPIST-1e  33.0    0   \n",
      "4        0004_01      Earth          0     F/1/S    TRAPPIST-1e  16.0    0   \n",
      "...          ...        ...        ...       ...            ...   ...  ...   \n",
      "8688     9276_01     Europa          0    A/98/P    55 Cancri e  41.0    1   \n",
      "8689     9278_01      Earth          1  G/1499/S  PSO J318.5-22  18.0    0   \n",
      "8690     9279_01      Earth          0  G/1500/S    TRAPPIST-1e  26.0    0   \n",
      "8691     9280_01     Europa          0   E/608/S    55 Cancri e  32.0    0   \n",
      "8692     9280_02     Europa          0   E/608/S    TRAPPIST-1e  44.0    0   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall  ...  VRDeck               Name  \\\n",
      "0             0.0        0.0           0.0  ...     0.0    Maham Ofracculy   \n",
      "1           109.0        9.0          25.0  ...    44.0       Juanna Vines   \n",
      "2            43.0     3576.0           0.0  ...    49.0      Altark Susent   \n",
      "3             0.0     1283.0         371.0  ...   193.0       Solam Susent   \n",
      "4           303.0       70.0         151.0  ...     2.0  Willy Santantines   \n",
      "...           ...        ...           ...  ...     ...                ...   \n",
      "8688          0.0     6819.0           0.0  ...    74.0  Gravior Noxnuther   \n",
      "8689          0.0        0.0           0.0  ...     0.0    Kurta Mondalley   \n",
      "8690          0.0        0.0        1872.0  ...     0.0       Fayey Connon   \n",
      "8691          0.0     1049.0           0.0  ...  3235.0   Celeon Hontichre   \n",
      "8692        126.0     4688.0           0.0  ...    12.0   Propsh Hontichre   \n",
      "\n",
      "     Transported  Earth  Europa  Mars  TRAP  PSO  Cancri  Groups  \n",
      "0              0      0       1     0     1    0       0    0001  \n",
      "1              1      1       0     0     1    0       0    0002  \n",
      "2              0      0       1     0     1    0       0    0003  \n",
      "3              0      0       1     0     1    0       0    0003  \n",
      "4              1      1       0     0     1    0       0    0004  \n",
      "...          ...    ...     ...   ...   ...  ...     ...     ...  \n",
      "8688           0      0       1     0     0    0       1    9276  \n",
      "8689           0      1       0     0     0    1       0    9278  \n",
      "8690           1      1       0     0     1    0       0    9279  \n",
      "8691           0      0       1     0     0    0       1    9280  \n",
      "8692           1      0       1     0     1    0       0    9280  \n",
      "\n",
      "[8693 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill data\n",
    "print(df['HomePlanet'].isna().sum()) #201 planetas faltando\n",
    "df['HomePlanet'] = df['HomePlanet'].fillna(df['Groups'].map(groupDict))\n",
    "#df['HomePlanet'][i] = list(groupDict[getGroup(i)])[0]\n",
    "print(df['HomePlanet'].isna().sum())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['Transported'], axis=1))\n",
    "y = np.array(df['Transported'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size = 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = cross_val_predict(RandomForestClassifier(random_state = 1), x_train, y_train, cv = 10, n_jobs=-1)\n",
    "acuracia_vc = round(accuracy_score(y_train, train_pred)*100, 2)\n",
    "acuracia_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Earth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rafael\\Desktop\\rafa\\comp\\SpaceTitanic\\train_model.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m full_data_model\u001b[39m.\u001b[39mfit(X,y) \u001b[39m#using entire train dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_preds \u001b[39m=\u001b[39m full_data_model\u001b[39m.\u001b[39;49mpredict(test_X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mPassengerId\u001b[39m\u001b[39m'\u001b[39m: test_X[\u001b[39m'\u001b[39m\u001b[39mPassengerId\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mTransported\u001b[39m\u001b[39m'\u001b[39m: test_preds})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m output\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39msubmission.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:832\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    812\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 832\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    834\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    872\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    873\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 874\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    876\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    877\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 605\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Earth'"
     ]
    }
   ],
   "source": [
    "#Submission block\n",
    "full_data_model = RandomForestClassifier(random_state = 1)\n",
    "full_data_model.fit(X,y) #using entire train dataset\n",
    "test_X = pd.read_csv('test.csv')\n",
    "# TODO Format test_X\n",
    "\n",
    "\n",
    "\n",
    "# End TODO\n",
    "test_preds = full_data_model.predict(test_X)\n",
    "output = pd.DataFrame({'PassengerId': test_X['PassengerId'], 'Transported': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
