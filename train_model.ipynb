{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCOBERTAS:\n",
    "- VIP importa\n",
    "    * ~50% dos Não-VIPs são transportados\n",
    "    * ~38% dos VIPs são transportados\n",
    "    * Mas está baixo na lista de prioridade para ser transportado\n",
    "        * Europa -> ~65% Transportados\n",
    "        * Earth -> ~41% Transportados -> é o HomePlanet com maior número de pessoas (3566) e todas são NÃO-VIPs\n",
    "        * Mars -> ~53% Transportados\n",
    "- Usando cabines para os planetas\n",
    "    * A B C T -> Europa\n",
    "    * G -> Earth\n",
    "- Cryosleep True ou age <= 12 implica nenhum gasto\n",
    "- Qualquer gasto implica em Cryosleep False\n",
    "- Msm grupo -> Msm Planeta\n",
    "- Msm sobrenome -> Msm Planeta\n",
    "\n",
    "### TESTAR\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\").dropna()\n",
    "\n",
    "#formatting data TODO ISSO VEM POR ULTIMO\n",
    "df['Transported'] = df['Transported'].map({False: 0, True: 1})\n",
    "df['Earth'] = np.select([df['HomePlanet'] == 'Earth'], [1], default = 0)\n",
    "df['Europa'] = np.select([df['HomePlanet'] == 'Europa'], [1], default = 0)\n",
    "df['Mars'] = np.select([df['HomePlanet'] == 'Mars'], [1], default = 0)\n",
    "df['CryoSleep'] = np.select([df['CryoSleep'] == True], [1], default = 0)\n",
    "df['VIP'] = np.select([df['VIP'] == True], [1], default = 0)\n",
    "df['TRAP'] = np.select([df['Destination'] == 'TRAPPIST-1e'], [1], default = 0)\n",
    "df['PSO'] = np.select([df['Destination'] == 'PSO J318.5-22'], [1], default = 0)\n",
    "df['Cancri'] = np.select([df['Destination'] == '55 Cancri e'], [1], default = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps us prove that everybody with the same last name has the same Home Planet.\n",
    "# The same applies to passenger groups.\n",
    "def buildHomePlanetDict(column, char, pos, dff):\n",
    "    '''Function that builds a dictionary that follows a <column, set<planets>> relation'''\n",
    "    dictionary = {}\n",
    "    for i in range(len(dff)):\n",
    "        try:\n",
    "            current = dff[column][i].split(char)[pos]\n",
    "            if current not in dictionary:\n",
    "                dictionary[current] = set()\n",
    "            if pd.isnull(dff['HomePlanet'][i]) == False:\n",
    "                dictionary[current].add(dff['HomePlanet'][i])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return dictionary\n",
    "\n",
    "groupDict = buildHomePlanetDict('PassengerId', '_', 0, df)\n",
    "nameDict = buildHomePlanetDict('Name', ' ', 1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "# Fill data\n",
    "print(df['HomePlanet'].isna().sum()) #201 planetas faltando\n",
    "# def fillHomePlanet(dictionary):\n",
    "#     for i in range(len(df)):\n",
    "#         if pd.isnull(df['HomePlanet'][i]) == True:\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['Transported'], axis=1))\n",
    "y = np.array(df['Transported'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size = 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = cross_val_predict(RandomForestClassifier(random_state = 1), x_train, y_train, cv = 10, n_jobs=-1)\n",
    "acuracia_vc = round(accuracy_score(y_train, train_pred)*100, 2)\n",
    "acuracia_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Earth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rafael\\Desktop\\rafa\\comp\\SpaceTitanic\\train_model.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m full_data_model\u001b[39m.\u001b[39mfit(X,y) \u001b[39m#using entire train dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_preds \u001b[39m=\u001b[39m full_data_model\u001b[39m.\u001b[39;49mpredict(test_X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mPassengerId\u001b[39m\u001b[39m'\u001b[39m: test_X[\u001b[39m'\u001b[39m\u001b[39mPassengerId\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mTransported\u001b[39m\u001b[39m'\u001b[39m: test_preds})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rafael/Desktop/rafa/comp/SpaceTitanic/train_model.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m output\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39msubmission.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:832\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    812\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 832\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    834\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    872\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    873\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 874\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    876\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    877\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 605\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Earth'"
     ]
    }
   ],
   "source": [
    "#Submission block\n",
    "full_data_model = RandomForestClassifier(random_state = 1)\n",
    "full_data_model.fit(X,y) #using entire train dataset\n",
    "test_X = pd.read_csv('test.csv')\n",
    "# TODO Format test_X\n",
    "\n",
    "\n",
    "\n",
    "# End TODO\n",
    "test_preds = full_data_model.predict(test_X)\n",
    "output = pd.DataFrame({'PassengerId': test_X['PassengerId'], 'Transported': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
